https://decisivedevops.com/understanding-kubernetes-emptydir-with-3-practical-use-cases-960f550e0e34/

## 📦 What is `emptyDir` in Kubernetes?

- **Definition**: A type of ephemeral volume created when a Pod is assigned to a Node.
- **Lifecycle**: Exists only for the lifespan of the Pod. Deleted when the Pod is removed.
- **Purpose**: Ideal for temporary data storage and sharing between containers in the same Pod.

---

## 🔑 Key Characteristics

- **Creation**: Automatically created when a Pod is scheduled.
- **Persistence**: Survives container crashes but not Pod deletion.
- **Shared Access**: All containers in a Pod can access the same `emptyDir`.
- **Mount Flexibility**: Containers can mount it at different paths.
- **Storage Medium**:
  - Default: Node’s disk or SSD.
  - Optional: RAM-backed (`emptyDir.medium: "Memory"`) for faster access.
- **Location on Node**: `/var/lib/kubelet/pods/{podid}/volumes/kubernetes.io~empty-dir/`

---

## ⚙️ Lifecycle Operations

### Node-Level
- Pod assignment triggers `emptyDir` creation.
- Storage medium depends on configuration (disk or memory).

### Pod-Level
- Volume is ready as soon as the Pod starts.
- Data remains intact across container restarts.
- Deleted permanently when the Pod is removed.

---

## 🛠️ 3 Practical Use Cases

### 1. **Log Aggregation and Processing**
- Containers write logs to `emptyDir`.
- A sidecar container reads and processes logs.
- Useful for temporary log storage before external export.

### 2. **In-Memory Data Processing**
- Use `emptyDir.medium: "Memory"` for high-speed operations.
- Ideal for caching, buffering, or intermediate computations.

### 3. **Batch Job Processing**
- Temporary storage for input/output files during job execution.
- Data discarded after job completion, reducing storage overhead.

---

## 🧠 Summary

`emptyDir` is a simple yet powerful tool for managing ephemeral data within Kubernetes Pods. 
It’s perfect for scenarios where data doesn’t need to persist beyond the Pod’s lifecycle and offers flexibility in both disk and memory-backed configurations.




Here’s the corrected manifest file first:  

```yaml
apiVersion: v1
kind: Pod
metadata:               # Defines metadata about the Pod
  name: example-pod     # Pod name
spec:                   # Specification (the desired state) of the Pod
  containers:           # List of containers the Pod will run
  - name: app-container # Name of the container
    image: busybox      # Container image to use
    command: ["sleep", "3600"]  # Command to run inside the container
    volumeMounts:       # Where to mount the volume in the container
    - mountPath: /data  # Path inside the container
      name: temp-storage  # References the volume defined below
  volumes:              # Defines the volumes attached to this Pod
  - name: temp-storage  # Volume name (must match volumeMount)
    emptyDir: {}        # Type of volume (ephemeral, lives only as long as the Pod)
```

***

### **Explanation of Each Field**

#### 1. **`apiVersion: v1`**
- Specifies which Kubernetes API version this manifest uses.
- `v1` is the stable API group for core Kubernetes resources like Pods, Services, ConfigMaps, etc.

#### 2. **`kind: Pod`**
- Tells Kubernetes that the object being defined is a **Pod**.
- A Pod is the smallest deployable unit in Kubernetes, and it can contain **one or more containers**.

#### 3. **`metadata`**
- Stores identifying data for this resource.
- **`name: example-pod`** means this Pod will be called `example-pod` in the cluster.
- Metadata can also include labels, annotations, and namespace info.

#### 4. **`spec`**
- Describes the desired configuration of the Pod.

***

### Inside `spec`

#### **`containers`**
- This is a list because a Pod can have multiple containers.
- **`name: app-container`** → The logical name for this container inside the Pod.
- **`image: busybox`** → Tells Kubernetes to pull the `busybox` container image from a registry.
- **`command: ["sleep", "3600"]`** → Overrides the container’s default command to keep it running for 3600 seconds.

#### **`volumeMounts`**
- **`mountPath: /data`** → Inside the container, the volume will be accessible at `/data`.
- **`name: temp-storage`** → Must match one of the volumes defined under `spec.volumes`.

***

#### **`volumes`**
- **`name: temp-storage`** → The internal name for the volume.
- **`emptyDir: {}`** → Creates an **ephemeral** volume on the **node’s local storage**:
  - It is empty when the Pod starts.
  - It exists as long as the Pod exists.
  - When the Pod is deleted or moved to another node, the data is lost.

Use cases for `emptyDir`:  
- Temporary scratch space.
- Sharing files between multiple containers in the same Pod.
- Caching intermediate build/process results.

***

### **Pod Lifecycle with This Manifest**
1. **Pod created** → Kubernetes schedules it to a node.
2. **`emptyDir` volume created** → Empty directory on that node’s storage created for `temp-storage`.
3. **Container starts** and mounts the `emptyDir` volume at `/data`.
4. Containers can read/write files to `/data`.
5. **Pod deleted** → The emptyDir storage is also deleted automatically.

***

✅ **In summary:**  
This manifest defines a single-container Pod running the `busybox` container image, with an ephemeral `emptyDir` volume mounted at `/data` inside the container. The volume is temporary and only exists while the Pod itself exists.

***

When you use an **emptyDir volume** and your Pod is running on **node2**, the data you write to `/data` inside the container is stored on the filesystem of node2 in a 
specific directory managed by Kubernetes—not just inside the container, but on the node itself[1][2][5].

- The files you see at `/data` in your container are actually stored in a directory on node2 at:  
  `/var/lib/kubelet/pods/{pod_uid}/volumes/kubernetes.io~empty-dir/{volume_name}/`[1][2][5]

kubectl get pod example-pod -n default -o jsonpath='{.metadata.uid}'

or 

Go to the worker node execute crictl ps > get the container > crictl inspect <container-id>

# crictl ps
CONTAINER           IMAGE               CREATED             STATE               NAME                ATTEMPT             POD ID              POD
e3a497dcc417b       6d3e4188a38af       3 minutes ago       Running             app-container       0                   c006055a56372       example-pod

# crictl inspect e3a497dcc417b 

        {
          "destination": "/data",   # This is the Volume (EmptyDir)
          "type": "bind",
          "source": "/var/lib/kubelet/pods/805e4615-85f4-4ab4-a1b9-ebbdd0a4ddf2/volumes/kubernetes.io~empty-dir/temp-storage",  # This is the path on the node.
          "options": [
            "rbind",
            "rprivate",
            "rw"
          ]
        },


[rheluser@master volume]$ kubectl exec -it example-pod -- sh -c "echo 'This is test for EmptyDir volume' > /data/app.log"

[root@worker-1 ~]# cd /var/lib/kubelet/pods/805e4615-85f4-4ab4-a1b9-ebbdd0a4ddf2/volumes/kubernetes.io~empty-dir/temp-storage
[root@worker-1 temp-storage]# ls -ltr
total 4
-rw-r--r--. 1 root root 33 Aug 10 17:02 app.log
[root@worker-1 temp-storage]# cat app.log 
This is test for EmptyDir volume



- This directory is created when the Pod is scheduled to node2, and all files written via `/data` inside your container exist as real files in this host path for as long as the Pod lives on node2 (container restarts don’t clear them)[7].
- You cannot access this data from outside the Pod directly (unless you log into node2 itself and visit the path above), but it means the storage and the data reside physically on node2’s disk or RAM, depending on configuration[3][7].

Key behaviors:
- If the Pod is deleted or evicted, the directory and all data inside it on node2 are removed permanently[3][5][6].
- If your Pod was rescheduled to another node (node1, for example), a new emptyDir is created there, and the files do not move—they are only stored on the node where the Pod currently runs[5][7].

So, as long as your Pod is running on node2, the /data contents exist on node2’s local disk under the kubelet’s management directory[1][2].

Sources:
- Kubernetes documentation on volumes and emptyDir[3][5][7]
- Learning Ocean detailed path info[1]
- NetApp volume types and behavior[6]

Sources
[1] Kubernetes - Volumes - Learning-Ocean https://learning-ocean.com/tutorials/kubernetes/kubernetes-volumes/
[2] How to Collect Log Data from Kubernetes Using emptyDir https://edgedelta.com/company/blog/how-to-collect-kubernetes-log-data-emptydir
[3] Volumes https://kubernetes.io/docs/concepts/storage/volumes/
[4] Does Kubernetes mount an emptyDir volume on the host? https://stackoverflow.com/questions/46525081/does-kubernetes-mount-an-emptydir-volume-on-the-host
[5] Understanding Kubernetes emptyDir — With 3 Practical Use ... https://decisivedevops.com/understanding-kubernetes-emptydir-with-3-practical-use-cases-960f550e0e34/
[6] 5 Types of Kubernetes Volumes and How to Work with Them https://www.netapp.com/learn/cvo-blg-5-types-of-kubernetes-volumes-and-how-to-work-with-them/
[7] Ephemeral Volumes https://kubernetes.io/docs/concepts/storage/ephemeral-volumes/
[8] Configure a Pod to Use a Volume for Storage https://kubernetes.io/docs/tasks/configure-pod-container/configure-volume-storage/

==

**emptyDir volume in memory**,
=============================

To store an **emptyDir volume in memory**, set `emptyDir.medium: "Memory"` in your Pod manifest; Kubernetes will mount a RAM-backed filesystem (tmpfs) as the volume, meaning all data is kept in node RAM[2][7][6].

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: memory-emptydir-pod
spec:
  containers:
  - name: app-container
    image: busybox
    command: ["sleep", "3600"]
    volumeMounts:
    - mountPath: /data
      name: ram-storage
  volumes:
  - name: ram-storage
    emptyDir:
      medium: Memory      # Uses RAM for data storage
      sizeLimit: 512Mi    # Optional: maximum size of the tmpfs volume
```

**Pod Life Cycle with memory-backed emptyDir:**
- When the Pod is scheduled, Kubernetes creates the tmpfs volume in RAM on the node[2][4].
- Data written to `/data` in the container is stored in node memory.  
- If the container restarts (due to a crash), files in memory remain available[2][4].
- If the Pod is deleted, evicted, or moved to another node, or if the node reboots, the RAM storage (tmpfs) is wiped and **all data is lost**[2][4][7]. This also includes loss from node restarts, not just Pod deletion.

**Key scenarios to be aware of:**
- Pod deletion or termination: data in tmpfs is erased[2][4].
- Node failure or reboot: RAM storage is cleared, so all volume data is lost[2][7].
- Suitable only for temporary workspace, caches, or fast data exchange within Pod lifetime—not for persistent storage.

Sources:
- Kubernetes official documentation[2]
- NetApp volume guide[7]
- Portworx ephemeral storage overview[6]
- DecisiveDevOps use-case breakdown[4]

Sources
[1] Memory EmptyDir tmpfs size capped at 100% of node RAM ... - GitHub https://github.com/kubernetes/kubernetes/issues/126617
[2] Volumes | Kubernetes https://kubernetes.io/docs/concepts/storage/volumes/
[3] emptyDir mounts to tmpfs by default · Issue #3609 - GitHub https://github.com/bottlerocket-os/bottlerocket/issues/3609
[4] Understanding Kubernetes emptyDir — With 3 Practical Use-cases https://decisivedevops.com/understanding-kubernetes-emptydir-with-3-practical-use-cases-960f550e0e34/
[5] Resource Management for Pods and Containers - Kubernetes https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
[6] Ephemeral Storage in Kubernetes: Overview & Guide - Portworx https://portworx.com/knowledge-hub/ephemeral-storage-in-kubernetes-overview-guide/
[7] 5 Types of Kubernetes Volumes and How to Work with Them | NetApp https://www.netapp.com/learn/cvo-blg-5-types-of-kubernetes-volumes-and-how-to-work-with-them/
[8] How to take tmpfs usage into account in Kubernetes resource ... https://stackoverflow.com/questions/71405477/how-to-take-tmpfs-usage-into-account-in-kubernetes-resource-allocation



EmptyDir() with Deployment or Replicaset
=======================================

No, an **emptyDir volume does not share data between pods** in a Deployment with multiple replicas. 

Each Pod in a Deployment gets its own separate instance of the emptyDir volume that is created afresh on the node where the Pod is scheduled.

Detailed explanation:
- **emptyDir** volume is *pod-scoped* and exists only for the lifetime of that specific Pod on a specific node. It is created empty when the Pod starts and deleted when the Pod is removed.
- In a Deployment with 3 replicas, Kubernetes creates 3 separate Pods, each with its own independent emptyDir volume.
- These volumes live on the node where each Pod is scheduled, and *are not shared* across Pods or nodes.
- As a result, data written in the emptyDir of one Pod is isolated and *cannot be accessed* by other Pods.

If you want to share data between replicas (pods) in a Deployment, you need to use a **shared persistent volume** like a PersistentVolumeClaim (PVC) backed by storage that supports sharing (e.g., NFS, Ceph, cloud shared disks) and mounted as `ReadWriteMany`.

**Summary:**

| Aspect                      | emptyDir Volume                        | Persistent Volume with PVC (shared)            |
|-----------------------------|-------------------------------------|------------------------------------------------|
| Scope                       | Pod (unique per Pod replica)         | Can be shared between multiple Pods            |
| Data visibility across Pods | No (isolated)                       | Yes (shared storage)                            |
| Lifetime                    | Pod lifetime                       | Independent of Pods, persistent                  |
| Use case                    | Temporary scratch space, cache      | Shared configuration, persistent data storage   |

This is consistent with Kubernetes official documentation stating emptyDir volumes are created newly for *each Pod* and deleted once the Pod is removed[1][3].

Sources:
- Kubernetes official docs on Volumes and emptyDir[1]
- Unofficial Kubernetes docs on emptyDir lifecycle[3]
- Practical knowledge of volume behavior in Deployments and replicasNo, an emptyDir volume is *not* shared between Pods in a Deployment with multiple replicas. Each Pod gets its own separate emptyDir volume created fresh on the node where that Pod runs. The emptyDir is scoped to the individual Pod lifecycle, so data written in one Pod’s emptyDir is isolated and cannot be accessed by other Pods.

To share data between multiple Pods (like 3 replicas in a Deployment), you would need a shared PersistentVolume backed by storage that supports multi-attach, such as NFS, Ceph, or a cloud file share, mounted via a PersistentVolumeClaim with ReadWriteMany access mode.

In short:

| Volume Type           | Shared Across Pods? | Lifecycle          | Typical Use Case                     |
|----------------------|--------------------|--------------------|------------------------------------|
| emptyDir             | No                 | Pod lifetime       | Temporary local storage per Pod    |
| PersistentVolumeClaim | Yes (if ReadWriteMany) | Independent       | Shared or persistent storage       |

So emptyDir is best suited for ephemeral, pod-local scratch or cache space, not cross-pod data sharing[1][3].

Sources
[1] Volumes | Kubernetes https://kubernetes.io/docs/concepts/storage/volumes/
[2] Kubernetes emptyDir is not the same as Docker's volumes-from https://www.fairwinds.com/blog/kubernetes-emptydir-not-the-same-as-dockers-volumes-from
[3] Volumes - Unofficial Kubernetes - Read the Docs https://unofficial-kubernetes.readthedocs.io/en/latest/concepts/storage/volumes/
[4] Ephemeral Volumes - Kubernetes https://kubernetes.io/docs/concepts/storage/ephemeral-volumes/
[5] Kubernetes persistent volume options - Outshift | Cisco https://outshift.cisco.com/blog/persistent-volumes-k8s
[6] Replicate docker-compose volume behavior in kubernetes https://stackoverflow.com/questions/57378980/replicate-docker-compose-volume-behavior-in-kubernetes
[7] How to K8s: Persistent and Ephemeral Volumes - MacStadium https://www.macstadium.com/blog/ephemeral-volumes
[8] debug: ability to replicate volume mounts · Issue #1071 - GitHub https://github.com/kubernetes/kubectl/issues/1071
[9] StatefulSets misunderstood or my ignorance? : r/kubernetes - Reddit https://www.reddit.com/r/kubernetes/comments/1691w3w/statefulsets_misunderstood_or_my_ignorance/


No, even if **all Pods with emptyDir volumes are scheduled on the same node**, each Pod gets its own separate emptyDir volume, isolated from the others. **emptyDir is scoped to a single Pod's lifecycle** and is not shared between Pods, regardless of whether they run on the same node or different nodes**.

Key points:
- The emptyDir volume is created fresh for each Pod on the node it is scheduled.
- Containers within the *same* Pod can share the emptyDir volume.
- Different Pods, even if on the same node, each get independent emptyDir directories.
- Data written in one Pod's emptyDir is not visible or accessible to another Pod.

If you want to share data between multiple Pods simultaneously (even on the same node), you need a shared persistent volume like a PersistentVolumeClaim backed by a network file system (e.g., NFS) or a shared storage solution that supports multi-attach access modes.

This is consistent with Kubernetes official behavior and confirmed by practical sources explaining emptyDir volumes are strictly Pod-local storage and not shared across Pods, even on the same node[1][2][4][5].

Hence:

| Scenario            | Data Sharing Between Pods with emptyDir on Same Node? |
|---------------------|-------------------------------------------------------|
| Multiple Pods on same node, each with emptyDir volume | No, isolated per Pod                                 |
| Multiple containers within the same Pod sharing emptyDir | Yes, shared among containers                          |

Sources:
- Kubernetes official docs on emptyDir volume lifecycle and usage[4][5]
- Practical Kubernetes blog explains emptyDir sharing is within single Pod containers only[1][2]
- Community examples confirm emptyDir is not shared between Pods, even on the same node[3]

Sources
[1] Kubernetes Pods Storage and Volume Sharing https://www.baeldung.com/ops/kubernetes-pods-share-storage
[2] How to Use EmptyDir Volumes on Kubernetes - Arun's blog https://arun944.hashnode.dev/kubernetes-volumes-emptydir
[3] MultiContainer with shared Volume as EmptyDir working ... https://stackoverflow.com/questions/77693075/multicontainer-with-shared-volume-as-emptydir-working-however-when-used-shared-v
[4] Volumes https://kubernetes.io/docs/concepts/storage/volumes/
[5] Understanding Kubernetes emptyDir — With 3 Practical Use ... https://decisivedevops.com/understanding-kubernetes-emptydir-with-3-practical-use-cases-960f550e0e34/
[6] Communicate Between Containers in the Same Pod Using ... https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/
[7] Can all my nodes and pods share a same read only ... https://www.reddit.com/r/kubernetes/comments/1mjy01r/can_all_my_nodes_and_pods_share_a_same_read_only/
[8] How to share data between containers with K8s ... https://www.spectrocloud.com/blog/how-to-share-data-between-containers-with-k8s-shared-volumes

# Multicontainer Pod ###
==============================

In a multi-container Pod using an **emptyDir** volume, you do **not** have to use the *same mount path* in each container, but you **must** use the **same volume name** under each container's `volumeMounts` 
to refer to the shared emptyDir volume defined in `spec.volumes`. 

Kubernetes will make that same volume (the shared emptyDir) available at the specified mount paths in each container individually, so different containers 
can mount it at different paths if you want.

### Summary:
- The volume name in `volumeMounts` must be the **same** across containers to share the `emptyDir` volume.
- The **mountPath** can be **different or same** in each container, depending on how you want the volume to be accessible inside each container's filesystem.

### Example:

```yaml
apiVersion: v1
kind: Pod
meta
  name: multi-container-pod
spec:
  volumes:
  - name: shared-data
    emptyDir: {}

  containers:
  - name: container-one
    image: busybox
    command: ["sleep", "3600"]
    volumeMounts:
    - name: shared-data
      mountPath: /data/container-one  # Mount path inside container one

  - name: container-two
    image: busybox
    command: ["sleep", "3600"]
    volumeMounts:
    - name: shared-data
      mountPath: /mnt/container-two  # Different mount path in container two
```



Both containers share the same `emptyDir` volume `shared-data`, but inside each container it is mounted at different paths. 
Files written by one container to the volume persist and are visible to the other container under their respective mount paths.

### Why this works:
- Kubernetes creates the `emptyDir` volume once per Pod.
- That volume is mounted into all containers that reference it by name.
- Each container can choose any path inside its filesystem (`mountPath`) to mount the shared volume.

### Source references:
- Kubernetes official docs state: "All containers in the Pod can read and write the same files in the emptyDir volume, though that volume can be mounted at the same or different paths in each container"[3].
- Examples and discussions on StackOverflow and kubermatic blog confirm volume name consistency with flexible mount paths in multi-container Pods[1][2].

So to directly answer your question:  
**No, you don't need the same mount path name**, but you *must* use the same volume name in `volumeMounts` to share the emptyDir volume between containers in the Pod.

Sources
[1] MultiContainer with shared Volume as EmptyDir working however ... https://stackoverflow.com/questions/77693075/multicontainer-with-shared-volume-as-emptydir-working-however-when-used-shared-v
[2] Volume and volumeMounts: An Introduction - Kubermatic https://www.kubermatic.com/blog/keeping-the-state-of-apps-1-introduction-to-volume-and-volumemounts/
[3] Volumes | Kubernetes https://kubernetes.io/docs/concepts/storage/volumes/
[4] Explaining the Difference Between subPath and mountPath in ... https://www.baeldung.com/ops/kubernetes-subpath-vs-mountpath
[5] Communicate Between Containers in the Same Pod Using a Shared ... https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/
[6] How to Use EmptyDir Volumes on Kubernetes - Arun's blog https://arun944.hashnode.dev/kubernetes-volumes-emptydir
[7] Configure a Pod to Use a Volume for Storage - Kubernetes https://kubernetes.io/docs/tasks/configure-pod-container/configure-volume-storage/
[8] Multi-Container Pods in Kubernetes https://linchpiner.github.io/k8s-multi-container-pods.html
[9] How to share data between containers with K8s shared volume https://www.spectrocloud.com/blog/how-to-share-data-between-containers-with-k8s-shared-volumes


An **emptyDir volume** in Kubernetes is created when a Pod is assigned to a node, and the actual data for that volume is stored on the node’s filesystem under this path, 
So volume_name will be shared between the container. Container mount path name can be different.

```
/var/lib/kubelet/pods/{pod_uid}/volumes/kubernetes.io~empty-dir/{volume_name}/
```

Here is the detailed explanation:

- When a Pod with an emptyDir volume is scheduled on a node, Kubernetes’ kubelet creates a directory on that node's local disk (or in memory if `emptyDir.medium: "Memory"` is set) specifically for that volume.
- This directory lives on the **node itself**, outside the container sandbox, and is managed by the kubelet.
- The container(s) inside the Pod see this storage mounted at the specified `mountPath` (e.g., `/data`), but the physical files actually reside on the node disk under the kubelet's directory tree.
- This volume exists **only as long as the Pod runs on that node**, and all containers within the same Pod share access to this same directory.
- If the Pod is deleted, evicted, or moved to another node, this directory and all its data are removed permanently from the node.
- Node-level access to this directory is possible if you have access to the node (e.g., via SSH), but the volume is isolated from other Pods—even on the same node.

Sources supporting this:

- "The volume lives on the host, outside of the container... The default mountPath for each pod has a root location of `/var/lib/kubelet/pods/{pod_uid}/volumes/kubernetes.io~empty-dir/`" [1].
- "The location should be `/var/lib/kubelet/pods/{podid}/volumes/kubernetes.io~empty-dir/` on the given node where your pod is running." [2].
- Kubernetes official docs: "For a Pod that defines an emptyDir volume, the volume is created when the Pod is assigned to a node... stored on whatever medium that backs the node such as disk, SSD, or network storage..." [3].
- StackOverflow confirms emptyDir data physically resides in `/var/lib/kubelet/pods/PODUID/volumes/kubernetes.io~empty-dir/VOLUMENAME` on the node [4].
- Lifecycle details confirm emptyDir is created at Pod assignment and deleted with Pod removal, storing data locally per node [5].

In summary, the emptyDir volume corresponds to a directory on the node under the kubelet's management directories, shared among containers in the Pod, and lasting only for that Pod's lifetime on that node.

Sources
[1] How to Collect Log Data from Kubernetes Using emptyDir https://edgedelta.com/company/blog/how-to-collect-kubernetes-log-data-emptydir
[2] Kubernetes - Volumes - Learning-Ocean https://learning-ocean.com/tutorials/kubernetes/kubernetes-volumes/
[3] Volumes https://kubernetes.io/docs/concepts/storage/volumes/
[4] Does Kubernetes mount an emptyDir volume on the host? https://stackoverflow.com/questions/46525081/does-kubernetes-mount-an-emptydir-volume-on-the-host
[5] Understanding Kubernetes emptyDir — With 3 Practical Use ... https://decisivedevops.com/understanding-kubernetes-emptydir-with-3-practical-use-cases-960f550e0e34/
[6] Ephemeral Volumes https://kubernetes.io/docs/concepts/storage/ephemeral-volumes/
[7] Configure a Pod to Use a Volume for Storage https://kubernetes.io/docs/tasks/configure-pod-container/configure-volume-storage/
[8] 5 Types of Kubernetes Volumes and How to Work with Them https://www.netapp.com/learn/cvo-blg-5-types-of-kubernetes-volumes-and-how-to-work-with-them/



# Test with multi container Pod with emptyDir
=============================================
To test a multi-container Pod sharing a volume using **emptyDir**, you can create a Pod manifest with two containers that both mount the same emptyDir volume
but at possibly different paths. One container writes data to the shared volume, and the other reads that data.

Here is a simple example manifest and steps to test:

```yaml
apiVersion: v1
kind: Pod
meta
  name: shared-emptydir-pod
spec:
  volumes:
  - name: shared-data
    emptyDir: {}
  containers:
  - name: writer
    image: busybox
    command: ["/bin/sh", "-c"]
    args:
      - while true; do date >> /mnt/shared/date.txt; sleep 5; done
    volumeMounts:
    - name: shared-data
      mountPath: /mnt/shared
  - name: reader
    image: busybox
    command: ["/bin/sh", "-c"]
    args:
      - while true; do cat /shared/date.txt; sleep 5; done
    volumeMounts:
    - name: shared-data
      mountPath: /shared
```

### How to Test

1. **Apply the Pod manifest:**
   ```bash
   kubectl apply -f shared-emptydir-pod.yaml
   ```

2. **Check Pod status:**
   ```bash
   kubectl get pod shared-emptydir-pod
   ```
   Wait until it is in the `Running` state.

3. **See logs of the reader container showing the data written by the writer container:**
   ```bash
   kubectl logs shared-emptydir-pod -c reader
   ```
   You should see the datetime entries appended by the `writer` container.

4. **Exec into either container to manually check the shared volume contents, e.g.:**
   ```bash
   kubectl exec -it shared-emptydir-pod -c writer -- sh
   ls /mnt/shared
   cat /mnt/shared/date.txt
   ```

5. **Confirm that changes made by one container are visible to the other, proving the shared nature of the emptyDir volume.**

***

### Explanation

- The `emptyDir` volume named `shared-data` is created when the Pod starts.
- Both containers mount this volume, but at different `mountPath`s (`/mnt/shared` and `/shared`).
- The `writer` container writes the current date continuously into a file inside the volume.
- The `reader` container reads this file continuously and outputs to its logs.
- Because emptyDir is shared among containers in the same Pod, the reader container sees the file updates in real-time.

***

This method is a common approach for testing shared volume usage in multi-container Pods using an `emptyDir` volume.

Sources:
- Arun's Kubernetes blog with examples of multi-container Pods sharing emptyDir volumes[1].
- Kubernetes official docs highlighting emptyDir as shared between containers in a Pod[2][6].
- Practical examples of shared logs or files between containers[5].

Sources
[1] How to Use EmptyDir Volumes on Kubernetes - Arun's blog https://arun944.hashnode.dev/kubernetes-volumes-emptydir
[2] Volumes | Kubernetes https://kubernetes.io/docs/concepts/storage/volumes/
[3] Understanding Kubernetes emptyDir — With 3 Practical Use-cases https://decisivedevops.com/understanding-kubernetes-emptydir-with-3-practical-use-cases-960f550e0e34/
[4] Configure a Pod to Use a Volume for Storage - Kubernetes https://kubernetes.io/docs/tasks/configure-pod-container/configure-volume-storage/
[5] MultiContainer with shared Volume as EmptyDir working however ... https://stackoverflow.com/questions/77693075/multicontainer-with-shared-volume-as-emptydir-working-however-when-used-shared-v
[6] Communicate Between Containers in the Same Pod Using a Shared ... https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/
[7] Multi-Container Pods in Kubernetes https://linchpiner.github.io/k8s-multi-container-pods.html
[8] How to share data between containers with K8s shared volume https://www.spectrocloud.com/blog/how-to-share-data-between-containers-with-k8s-shared-volumes
[9] Kubernetes Storage Made Easy: Kubernetes & Persistent Volume https://devtron.ai/blog/kubernetes-storage-made-easy-kubernetes-volumes-persistent-volumes/

